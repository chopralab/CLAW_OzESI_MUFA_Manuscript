{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.CLAW_OzESI import Parse\n",
    "from scripts.CLAW_OzESI_filter import OzESIFilter\n",
    "from scripts.CLAW_plot import CLAWPlot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Update the paths with your file locations:\n",
    "# data_base_name_location = \"/scratch/negishi/iyer95/iyer95/CLAW_OzESI_Paper/CLAW/lipid_platform/lipid_database/Lipid_Database.xlsx\"\n",
    "# Project_Folder_data = \"/scratch/negishi/iyer95/iyer95/CLAW_OzESI_Paper/CLAW/lipid_platform/Projects/canola/mzml\"\n",
    "# Project_results = \"/scratch/negishi/iyer95/iyer95/CLAW_OzESI_Paper/CLAW/lipid_platform/Projects/canola/results\"\n",
    "# file_name_to_save = \"parsed_results\"\n",
    "# tolerance = 0.3\n",
    "\n",
    "# # Create an instance of the Parse class with these paths and parameters.\n",
    "# parser = Parse(\n",
    "#     data_base_name_location=data_base_name_location,\n",
    "#     Project_Folder_data=Project_Folder_data,\n",
    "#     Project_results=Project_results,\n",
    "#     file_name_to_save=file_name_to_save,\n",
    "#     tolerance=tolerance,\n",
    "#     remove_std=True,\n",
    "#     save_data=False,          # Change to True if you want to save the parsed CSV\n",
    "#     batch_processing=True,    # True for processing a folder of mzML files\n",
    "#     plot_chromatogram=True    # Set to False if you do not need chromatogram plotting\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"/scratch/negishi/iyer95/iyer95/CLAW_OzESI_Paper\")\n",
    "from ASPIRE_LINQX.ai.chains.microservice import module_to_microservice\n",
    "from ASPIRE_LINQX.ai.agents.core import create_linqx_chat_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from ASPIRE_LINQX.ai.chains.microservice import module_to_microservice, object_to_microservice\n",
    "from ASPIRE_LINQX.testing.models.drivers import MicrowaveSynthesizer as MSModule\n",
    "from ASPIRE_LINQX.testing.models.drivers.MicrowaveSynthesizerObject import MicrowaveSynthesizer as MSObject\n",
    "from ASPIRE_LINQX.ai.agents.core import create_linqx_chat_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "# from agent_scripts.peak_test import ParquetLoader\n",
    "# #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_OzESI_matched = pd.read_csv('df_OzESI_matched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_manual_data = {\n",
    "    'TG': ['TG(52:2)', 'TG(52:3)', 'TG(52:4)', 'TG(54:2)', 'TG(54:3)', 'TG(54:4)', 'TG(54:5)'],\n",
    "    'Crude': [3.50, 2.10, 2.45, 4.00, 4.70, 3.60, 5.20],\n",
    "    'Degummed': [3.40, 3.00, 2.30, 2.90, 4.60, 4.00, 5.40],\n",
    "    'RBD': [4.00, 2.20, 2.00, 4.20, 4.50, 4.00, 4.30]\n",
    "}\n",
    "\n",
    "\n",
    "ms_object = CLAWPlot(manual_data=custom_manual_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"\\n    Create a command from the below information. \\n    Do not include any parameters that are not in the function signature.\\n    If the function signature denotes that it returns something, check to docstring to find the return signature.\\n\\n    Function name: plot_ratio_comparison\\n    Microservice: CLAWPlot\\n    UUID: 6bfeccf6-ebcd-41d1-a04b-085e8ebbfdf6\\n    Function Signature: (df_sample_ratio: str, plot_title: str, caitlin_column: str)\\n    Docstring: Plots and compares the CLAW ratio data (from a CSV file) with the manual data.\\n\\nThis method reads the sample ratio data from a CSV file whose path is provided as a string.\\nIt then plots:\\n    - The sample data (CLAW Ratio) using the 'Lipid' column (x-axis) and 'Ratio' column (y-axis).\\n    - The manual data (Caitlin data) using the 'TG' column (x-axis) and the specified 'caitlin_column' (y-axis)\\n      from the manual data provided at initialization.\\n\\nThe plot is formatted with a title, axis labels, legend, and gridlines, and is saved as a PNG file\\n(300 dpi) in the current directory with a filename based on the provided plot title.\\n\\nParameters:\\n    df_sample_ratio (str): CSV file path for the sample ratio data.\\n    plot_title (str): Title for the plot (and used in the output filename).\\n    caitlin_column (str): Column name in the manual data to be plotted.\\n    \", 'text': {'name': 'plot_ratio_comparison', 'microservice': 'CLAWPlot', 'desc': 'Plots and compares the CLAW ratio data (from a CSV file) with the manual data.', 'uuid': '6bfeccf6-ebcd-41d1-a04b-085e8ebbfdf6', 'parameters': {'df_sample_ratio': {'name': 'df_sample_ratio', 'data_type': 'str', 'desc': 'CSV file path for the sample ratio data.'}, 'plot_title': {'name': 'plot_title', 'data_type': 'str', 'desc': 'Title for the plot (and used in the output filename).'}, 'caitlin_column': {'name': 'caitlin_column', 'data_type': 'str', 'desc': 'Column name in the manual data to be plotted.'}}, 'has_return': True, 'return_signature': {'plot': 'The generated plot comparing CLAW ratio data with manual data.'}}}\n"
     ]
    }
   ],
   "source": [
    "object_driver_microservice = object_to_microservice(object=ms_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_agent_no_mem = create_linqx_chat_agent(\n",
    "    microservice=object_driver_microservice,\n",
    "    llm=ChatOpenAI(model='gpt-4', temperature=0),\n",
    "    use_memory=None,\n",
    "    human_interaction=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The human has provided all the necessary parameters to use the 'plot_ratio_comparison' tool. I will use these parameters to form the action.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "    \"action\": \"plot_ratio_comparison\",\n",
      "    \"action_input\": {\n",
      "        \"df_sample_ratio\": \"df_crude_ratio.csv\",\n",
      "        \"plot_title\": \"Crude\",\n",
      "        \"caitlin_column\": \"Crude\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\u001b[0mPNG saved as 'canola_paper_Crude.png' in the directory.\n",
      "\u001b[36;1m\u001b[1;3mNone\u001b[0m\u001b[32;1m\u001b[1;3mSince I'm an AI model, I don't have the capability to observe the result of the action. However, if the action was successful, a plot comparing the CLAW ratio data and the manual data should have been created with the title 'Crude' and saved as a PNG file in the current directory. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The plot_ratio_comparison method has been run with the provided parameters. If successful, a plot titled 'Crude' comparing the CLAW ratio data and the manual data should have been created and saved as a PNG file in the current directory.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = ms_agent_no_mem.invoke({\n",
    "    \"input\": (\n",
    "        \"Instantiate the CLAWPlot class from CLAW_plot.py and run its plot_ratio_comparison method \"\n",
    "        \"using the CSV file 'df_crude_ratio.csv' as input. Use the following parameters: \"\n",
    "        \"plot_title='Crude', caitlin_column='Crude'.\"\n",
    "    )\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pufaAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
