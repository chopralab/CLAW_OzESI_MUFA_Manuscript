{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kursawe Function Optimization via Apptainer Microservice\n",
    "\n",
    "In this notebook we will demonstrate how to using LINQX infrastructure to run closed-loop optimization jobs on containerized microservices run via Apptainer. There are 3 main learning objectives in this notebook.\n",
    "\n",
    "1. How to containerize microservices using Apptainer in a manner that is compatible with LINQX `ApptainerDriverCommand` objects\n",
    "2. How to build `ApptainerDriverCommand` objects which can create and interact with Apptainer instances\n",
    "3. How to build `ApptainerDriverCommand` objects into a workflow which can be run for closed-loop optimization using the EvoTorch optimization package\n",
    "\n",
    "### Other Notebooks\n",
    "- See `ideal_gas_law_opt.ipynb` for a tutorial on the basic LINQX infrastructure components\n",
    "- See `interactive_gas_law_opt.ipynb` for a tutorial on how to build and run workflows/optimization with interactive commands\n",
    "- See `optimize_mol.ipynb` for a tutorial on how to build and run workflows/optimization with containerized microservices using Docker\n",
    "\n",
    "### Requirements\n",
    "Please make sure that have the following dependencies installed\n",
    "- `pydantic version 2.3.0`\n",
    "- `torch version 2.0.1`\n",
    "- `evotorch version latest`\n",
    "- `matplotlib version latest`\n",
    "- `pandas version latest`\n",
    "- `spython version latest`\n",
    "\n",
    "### Background\n",
    "\n",
    "The Kursawe function is a function which can be used to test an optimization algorithms ability to perform multi-object optimization.\n",
    "\n",
    "The Kursawe function is defined as follows\n",
    "\n",
    "```python\n",
    "min (\n",
    "    sum(i,1,2) [-10 * exp(-0.2 * sqrt((x_i)^2 + (x_(i+1))^2))], # function 1\n",
    "    sum(i,1,3) [|x_i|^0.8 + 5 * sin((x_i)^3)] # function 2\n",
    ")\n",
    "```\n",
    "With bounds of\n",
    "```python\n",
    "-5 <= x_i <= 5\n",
    "1 <= i <= 3\n",
    "```\n",
    "\n",
    "### Kursawe Python Script\n",
    "\n",
    "We provide a python script (`microservices/kursawe.py`) which has two endpoints accessed via command line arguments:\n",
    "1. `--f1` corresponding to `function 1`\n",
    "2. `--f2` corresponding to `fucnction 2`\n",
    "\n",
    "The `kursawe.py` script also takes one additional required argument `--Vector` which is designed to take in a list corresponding to `x_1` through `x_3`\n",
    "\n",
    "It is important that all endpoints of your python script provide output in JSON format. For example in the Kursawe python script our endpoints provide output in the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"f1\": 0.000\n",
    "}\n",
    "```\n",
    "\n",
    "### Kursawe Definition File\n",
    "\n",
    "We also provide a definition file (`microservices/kursawe.def`) which can be used by Apptainer to build a image that can run our Kursawe microservice functions as various applications. A few notes about how this definition file needs should be structured to be compatible with LINQX infrastructure:\n",
    "\n",
    "1. All input parameters that are needed for a microservice to run should be passed in as enviroment varaibles if possible. For example in the Kursawe microservice we supply the vector from the environemnt varaible `$VECTOR`.\n",
    "\n",
    "    ```bash\n",
    "    python kursawe.py --f1 --f2 --vector=\"$VECTOR\"\n",
    "    ```\n",
    "\n",
    "    With the ability to set default values in the environment section\n",
    "\n",
    "    ```bash\n",
    "    %environment\n",
    "        export VECTOR=\"[0,1,2]\"\n",
    "    ```\n",
    "\n",
    "2. We reccomend defining an app for each endpoint of the microservice. For example in the Kursawe microservice we have two apps, one for running each function.\n",
    "\n",
    "    ```bash\n",
    "    %apprun f1 # Runs function 1\n",
    "        conda run -n torch_env python /kursawe.py --f1 --vector=\"$VECTOR\"\n",
    "    \n",
    "    %apprun f2 # runs function 2\n",
    "        conda run -n torch_env python /kursawe.py --f2 --vector=\"$VECTOR\"\n",
    "    ```\n",
    "\n",
    "3. If you want to provide the user the ability to run all applications at once, we reccomend doing this in the runscript\n",
    "\n",
    "    ```bash\n",
    "    %runscript # Runs function 1 and function 2\n",
    "        conda run -n torch_env python /kursawe.py --f1 --f2 --vector=\"$VECTOR\"\n",
    "    ```\n",
    "\n",
    "\n",
    "### Building the Image\n",
    "\n",
    "To build the Apptainer image which will be used in this notebook, navigate over to the `microservices` folder and run the following command\n",
    "\n",
    "```bash\n",
    "apptainer build kursawe.sif kursawe.def\n",
    "```\n",
    "\n",
    "Please be paitent as the container builds as it may take a while to download and install required Anaconda packages.\n",
    "\n",
    "Once the image is finsihed building you should see the `kursawe.sif` file in `microservices` directory. You are now ready to proceede to the next steps.\n",
    "\n",
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../JSON/\")\n",
    "\n",
    "from models.parameter.base import ParameterModel\n",
    "from models.command.container import ApptainerDriverCommand\n",
    "from models.workflow.base import BaseDriverWorkflow\n",
    "from models.optimizer.base import BaseObjectiveFunction\n",
    "\n",
    "import torch\n",
    "from evotorch import Problem\n",
    "from evotorch.algorithms import SteadyStateGA\n",
    "from evotorch.operators import GaussianMutation\n",
    "from evotorch.logging import PandasLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `ParameterModel` Object and `Parameter` Class\n",
    "\n",
    "The Kursawe function will take in a vector of length 3 so we need to define a `ParameterModel` object which can provide a template for the vector.\n",
    "\n",
    "After that we convert the `ParameterModel` object to a `Parameter` class using the `.to_param()` method which gives us a way to build vectors which are confined to the bounds we set in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter model for kursawe optimization\n",
    "vector_model = ParameterModel(\n",
    "    name='Vector',\n",
    "    data_type='float',  # The vector is a list of floats\n",
    "    upper_limit=5,      # The upper bound of the optimization problem is 5\n",
    "    lower_limit=-5,     # The lower bound of the optimization problem is -5\n",
    "    default=[0,0,0],    # Give all vectors a default of [0,0,0]\n",
    "    is_list=True        # The vector is a list\n",
    ")\n",
    "\n",
    "# Create the parameter class\n",
    "Vector = vector_model.to_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `ApptainerDriverCommand` Objects\n",
    "\n",
    "After building the `Parameter` class for the vector, we must define an `ApptainerDriverCommand` for each instance of a microservice which we want to run. This is designed to work with parallelization as each command is linked to its own instance of the microservice. When you call the command on parameters (`__call__` override), it will run the command as it is specified in its definition.\n",
    "\n",
    "Here we set up two `ApptainerDriverCommand`, one for running the `f1` app and another for running the `f2` app. `ApptainerDriverCommand` objects can also be set up to run the runscript or run specific apps at execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = \"../microservices/kursawe.sif\"\n",
    "# Build a command for running f1 of the kursawe microservice (app f1)\n",
    "f1 = ApptainerDriverCommand(\n",
    "    name='run_function_1',\n",
    "    parameters={\n",
    "        \"VECTOR\": Vector()                  # The only parameter is the vector\n",
    "    },\n",
    "    uuid=\"cluster\",                         \n",
    "    image_name=IMAGE_NAME, # The path to the .sif file\n",
    "    fn=None,\n",
    "    run_app=True,                           # We are running an app of the instance\n",
    "    app='f1',                               # The app we are running is f1 (function 1)\n",
    "    start_delay=0,                          # There is no need to have a start delay\n",
    "    has_return=True,                        # We are expecting a result to be returned\n",
    ")\n",
    "\n",
    "# Build a command for running f2 of the kursawe microservice (app f2)\n",
    "f2 = ApptainerDriverCommand(\n",
    "    name='run_function_2',\n",
    "    parameters={\n",
    "        \"VECTOR\": Vector()   \n",
    "    },\n",
    "    uuid=\"cluster\",\n",
    "    fn=None,\n",
    "    image_name=IMAGE_NAME,\n",
    "    run_app=True,\n",
    "    app='f2',                               # We now want to run the f2 app instead of f1\n",
    "    start_delay=0,\n",
    "    has_return=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run the runscript of the Apptainer image by setting the `run_script` attribute of the `ApptainerDriverCommand` object to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a command for running f1 and f2 of the kursawe microservice (runscript)\n",
    "f1_and_f2= ApptainerDriverCommand(\n",
    "    name=\"run_function_1_and_2\",\n",
    "    parameters={\n",
    "        \"VECTOR\": Vector()\n",
    "    },\n",
    "    uuid=\"cluster\",\n",
    "    fn=None,\n",
    "    image_name=IMAGE_NAME,\n",
    "    run_script=True,\n",
    "    start_delay=0,\n",
    "    has_return=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Apptainer Instances Linked to the Commands\n",
    "\n",
    "You can start an instance associated with a specific command by calling the `.start()` method. This will start a new Apptainer instances of the image defined in the command and assign that instance to the `ApptainerDriverCommand` (`._instance` attribute). \n",
    "\n",
    "Note that it is not required to call the `.start()` method prior to running the command as the `__call__` override will start a new instance if no instance is currently assign to the command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the microservices (instances) linked to each command\n",
    "f1.start()\n",
    "f2.start()\n",
    "f1_and_f2.start()\n",
    "for x in f1._client.instances(quiet=True): print(x.name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping Apptainer Instances Linked to the Commands\n",
    "\n",
    "If you need to stop an Apptainer instance that is associated with a specific `ApptainerDriverCommand` you can call the `.stop()` method. This will stop the current instance that is associated with the `ApptainerDriverCommand` but another instance can be started for the commmand by calling the `.start()` method or by just calling the command (`__call__` override)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the microservices (instances) linked to each command\n",
    "f1.stop()\n",
    "f2.stop()\n",
    "f1_and_f2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Apptainer Instances Linked ot the Commands\n",
    "\n",
    "To run microservices that are linked to `ApptainerDriverCommand` objects all that needs to be done is to call the object as a function (`__call__` override) with the appropriate parameters passed in as arguments. \n",
    "\n",
    "Since we set the parameter `VECTOR` to take in a vector of length 3, we call `f1`, `f1`, and `f1_and_f2` with a vector of length 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = f1(VECTOR=[-1,3,4])\n",
    "output_2 = f2(VECTOR=[-1,3,4])\n",
    "output_1_2 = f1_and_f2(VECTOR=[-1,3,4])\n",
    "print(f\"Output of running app f1: {output_1}\")\n",
    "print(f\"Output of running app f2: {output_2}\")\n",
    "print(f\"Output of running runscript: {output_1_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Workflow using Apptainer Based Microservices\n",
    "\n",
    "We can build our commands into a `DriverWorkflow` object which can be used for closed-loop optimization. This workflow will take in a list of `DriverCommand` objects which will be executed in linear order.\n",
    "\n",
    "After initalization of the `DriverWorkflow`, we can run the workflow using the `.exec()` method and providing appropraite values for the `list_kwargs` and `list_save_vars` arguments:\n",
    "\n",
    "- `list_kwargs`: This argument is designed to take in a list of argument mappings that will mapped into each command in the workflow at runtime. If we do not want to provide any arguments for a specific command at runtime we set the position in the list corresponding to that command to `None`. \n",
    "\n",
    "- `list_save_vars`: This argument is designed to take in a list of varaibles to save off from the JSON output of each command (provide as a dictionary of string keys and string values) to a workflows set of global varaibles. If no varaibles are supposed to be saved off for a specific command, we set the position in the list corresponding to that command to `None`.\n",
    "\n",
    "For example in the Kursawe workflow, we want to provide both `f1` and `f2` with the same vector (`{\"VECTOR\": [-1,3,4]}`) and we want to save off the output of `f1` in the workflow globals with the key `\"f1\"` and `f2` with the key `\"f2\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Workflow corresponding to Kursawe function\n",
    "kursawe_workflow = BaseDriverWorkflow(\n",
    "    name=\"kursawe_workflow\",\n",
    "    commands=[\n",
    "        f1,\n",
    "        f2,\n",
    "    ],\n",
    ")\n",
    "workflow_output = kursawe_workflow.exec(\n",
    "    list_kwargs=[\n",
    "        {\"VECTOR\": [-1,3,4]},\n",
    "        {\"VECTOR\": [-1,3,4]},\n",
    "    ],\n",
    "    list_save_vars=[\n",
    "        {\"f1\":\"f1\"},\n",
    "        {\"f2\":\"f2\"}\n",
    "    ]\n",
    ")\n",
    "print(workflow_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Objective (Fitness) Function using a Workflow\n",
    "\n",
    "In order to run closed-loop optimiation on your Apptainer microservices, you need to build your microservice workflow into a objective (fitness) function that is compatible with the optimization package of your choice.\n",
    "\n",
    "In this notebook, we are using the EvoTorch optimization package to optimize our workflow. Thus we use the `BaseObjectiveFunction` class which is compatible with EvoTorch optimizers. This class has the following attributes:\n",
    "\n",
    "- `workflow`: This argument should be the workflow object that will be called (via `.exec()` method) in this objective function\n",
    "\n",
    "- `order_kwargs`: This argument should corresponds to a list of positions (tuple) of objective function tensor input will be applied to certian commands in the workflow\n",
    "\n",
    "- `list_save_vars`: Same as previous `list_save_vars` argument\n",
    "\n",
    "- `fitness_criteria`: This argument should be a list of varaibles to access from the workflow globals and assess as fitness function criteria during optimization\n",
    "\n",
    "For this example we assign the `workflow` to our `kursawe_workflow` we built, `order_kwargs` to set the `VECTOR` parameter to all positions of the input tensor, `list_save_vars` to save off the output of both function, and `fitness_criteria` to be the output of both functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kursawe_obj_fn = BaseObjectiveFunction(\n",
    "    name=\"kursawe_obj_fn\",\n",
    "    workflow= kursawe_workflow,\n",
    "    order_kwargs= [\n",
    "        {\"VECTOR\": (0,3)},\n",
    "        {\"VECTOR\": (0,3)},\n",
    "    ],\n",
    "    list_save_vars=[\n",
    "        {\"f1\":\"f1\"},\n",
    "        {\"f2\":\"f2\"},\n",
    "    ],\n",
    "    fitness_criteria=[\"f1\",\"f2\"]\n",
    ")\n",
    "\n",
    "print(f\"Objective function output tensor: {kursawe_obj_fn(torch.Tensor([-1,3,4]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of the Objective Function using EvoTorch\n",
    "\n",
    "After wrapping the workflow in a fitness function that is compatible with the chosen optimization package, we need to define how the optimization algorithm traverse the search space defined by our function. Using EvoTorch, this is accomplished in the following manner:\n",
    "\n",
    "1. Defining a Problem: The `Problem` class is designed to define a search spaces and its bounds. We need to create one which is designed to search the space defined by our objective function.\n",
    "\n",
    "2. Defining a Search Algorithm: We need to have some form of search algorithm which will traverse the space defined by our problem in a directed manner. We choose the `SteadyStataGA` class and tell it to use the `GuassianMutation` operator providing us with a basic evolutionary algorithm. We set the size of the population to 10, meaning that it will initalize and run 10 seperate traversals through the search space\n",
    "\n",
    "3. Run the Search Algorithm: We will run each population member of the search algorithm for a specific number of steps allowing it to traverse through the space in a directed manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the problem which contains our search space\n",
    "problem = Problem(\n",
    "    objective_sense=[\"min\",\"min\"],      # In the Kursawe function we want to minimize both f1 and f2\n",
    "    objective_func=kursawe_obj_fn,      # We want the objective function to be the objective function we created\n",
    "    bounds=(\n",
    "        Vector().lower_limit,           # Our lower limit is based on our Vector parameter (-5)\n",
    "        Vector().upper_limit,           # Out upper limit is based on our Vector paramter (5)\n",
    "    ),\n",
    "    solution_length=3,                  # The input vector to the Kursawe function has 3 positions\n",
    ")\n",
    "\n",
    "# Define the search algorithm \n",
    "searcher = SteadyStateGA(\n",
    "    problem=problem, \n",
    "    popsize=10                          # Our search algorithm will keep track of 10 simultaneous runs\n",
    ")  \n",
    "\n",
    "# Have the sarch algorithm use the guassian mutation operator\n",
    "searcher.use(\n",
    "    GaussianMutation(problem,stdev=0.1) # Our guassian mutation operator will have a standard devation of 0.1\n",
    ")\n",
    "logger = PandasLogger(searcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going the run each seed of the search algorithm for 10 iterations. This may take a couple of miniutes depending on your system specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Optimiation Results\n",
    "\n",
    "Now lets see how well we were able to optimize the two objective over the 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = logger.to_dataframe()\n",
    "print(eval_df)\n",
    "eval_df[\"obj0_pop_best_eval\"].plot(alpha=0.4, marker=\".\", label=\"Function 1\")\n",
    "eval_df[\"obj1_pop_best_eval\"].plot(alpha=0.4, marker=\".\", label=\"Function 2\")\n",
    "plt.legend(title=\"Function\")\n",
    "plt.ylabel(\"F(x)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.title(\"Kursawe Function Optimization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the results of all of the seeds after 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for elem in searcher.population: results.append(list(elem.access_evals()))\n",
    "population_df = pd.DataFrame(results).astype(float)\n",
    "population_df = population_df.set_axis([\"objective_0\", \"objective_1\"], axis=1)\n",
    "print(population_df)\n",
    "plt.clf()\n",
    "plt.scatter(population_df[\"objective_0\"], population_df[\"objective_1\"], alpha=0.4, color=\"g\")\n",
    "plt.xlabel(\"F1(x)\")\n",
    "plt.ylabel(\"F2(x)\")\n",
    "plt.title(\"Kursawe Optimization Population Seed Values after 10 Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microservices that run on GPU\n",
    "\n",
    "There are instances where microservices need GPU access to function correctly. While the Kursawe optimization example that was previously shown does not, we have created a simple image from Nvidia base CUDA image which need GPU access to run correctly.\n",
    "\n",
    "Go ahead and build `nvidia_smi.sif` from `nvidia_smi.def` located in the `microservices` folder\n",
    "\n",
    "```bash\n",
    "apptainer build nvidia_smi.sif nvidia_smi.def\n",
    "```\n",
    "\n",
    "The runscript of this image is set to run the `nvidia-smi` command which will show system GPU information if the container has access to system GPU, otherwise it will fail.\n",
    "\n",
    "\n",
    "We start by creating a command without GPU access and running it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVIDIA_IMAGE_NAME = '../microservices/nvidia_smi.sif'\n",
    "nvidia_smi_no_gpu = ApptainerDriverCommand(\n",
    "    name='nvidia-smi',\n",
    "    uuid=\"cluster\",                         \n",
    "    image_name=NVIDIA_IMAGE_NAME, # The path to the .sif file\n",
    "    fn=None,\n",
    "    run_script=True,                            # We are running the runscript of the instance                           \n",
    "    start_delay=0,                              # There is no need to have a start delay                         \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "nvidia_smi_no_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets set the commands `gpu` attribute to True and see if the output changes and we can see the GPU listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_smi_gpu = ApptainerDriverCommand(\n",
    "    name='nvidia-smi',\n",
    "    uuid=\"cluster\",                         \n",
    "    image_name=NVIDIA_IMAGE_NAME, # The path to the .sif file\n",
    "    fn=None,\n",
    "    run_script=True,                            # We are running the runscript of the instance                           \n",
    "    start_delay=0,                              # There is no need to have a start delay               \n",
    "    gpu=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "nvidia_smi_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that GPU drivers are mount upon instance start, so if you do not start or run the command initially with GPU you will need to restart the commands instance (`.start()`) to get the GPU driver mount.\n",
    "\n",
    "### Stopping Instances\n",
    "\n",
    "It is important to note that Apptainer instances linked to commands are not automatically stopped upon exiting any Python script or Jupyter notebook. They will need to be stopped via the `ApptainerDriverCommand` objects `.stop()` method. \n",
    "\n",
    "You can also stop all instances with the following command\n",
    "\n",
    "```bash\n",
    "apptainer instance stop --all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1.stop()\n",
    "f2.stop()\n",
    "f1_and_f2.stop()\n",
    "nvidia_smi_no_gpu.stop()\n",
    "nvidia_smi_gpu.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested\n",
    "```\n",
    "Python 3.10.13\n",
    "apptainer version 1.1.7-1.el7\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
